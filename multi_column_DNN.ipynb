{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multi_column_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpBDUUPWmYwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf06ed24-d6da-48b9-f7f8-37e56dc6ad0a"
      },
      "source": [
        "#from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import torch\n",
        "from keras.utils import np_utils\n",
        "size_image = [28, 56, 100]\n",
        "drive.mount('/content/drive')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "from keras.datasets import mnist\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERJA_CkDmYwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c21467-cd62-46ed-e3cc-1c2f16a8c61c"
      },
      "source": [
        "label = len(set(list(Y_train)))\n",
        "Y_test = torch.from_numpy(Y_test)\n",
        "Y_test = torch.tensor(Y_test, dtype = torch.long).to(device)\n",
        "Y_train = torch.from_numpy(Y_train)\n",
        "Y_train = torch.tensor(Y_train, dtype = torch.long).to(device)\n",
        "print(\"Y_train shape is : {}\".format(Y_train.shape))\n",
        "print(\"Y_test shape is : {}\".format(Y_test.shape))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y_train shape is : torch.Size([60000])\n",
            "Y_test shape is : torch.Size([10000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhUR5VamYwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd400cb-786d-4830-e8d4-3330fbe46b81"
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional\n",
        "from torch.optim import Adam\n",
        "from torch.optim import SGD\n",
        "from torch.nn import Softmax\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, row, col):\n",
        "    super().__init__()\n",
        "    self.row = row\n",
        "    self.col = col\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)\n",
        "    self.conv2 = nn.Conv2d(32, 32, 3, padding = 1)\n",
        "    self.linear1 = nn.Linear(int(row / 4 ) * int(col / 4) * 32, 128)\n",
        "    self.linear2 = nn.Linear(128, 128)\n",
        "    self.linear3 = nn.Linear(128, label)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "  def forward(self, data):\n",
        "    data = self.pool(functional.relu(self.conv1(data)))\n",
        "    data = self.pool(functional.relu(self.conv2(data)))\n",
        "    data = torch.flatten(data, 1)\n",
        "    data = functional.relu(self.linear1(data))\n",
        "    data = functional.relu(self.linear2(data))\n",
        "    data = self.linear3(data)\n",
        "    #data = self.softmax(data)\n",
        "    return data\n",
        "class Model2(nn.Module):\n",
        "  def __init__(self, row, col):\n",
        "    super().__init__()\n",
        "    self.row = row\n",
        "    self.col = col\n",
        "    self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)\n",
        "    self.linear1 = nn.Linear(int(row / 2 ) * int(col / 2) * 32, 128)\n",
        "    self.linear2 = nn.Linear(128, 128)\n",
        "    self.linear3 = nn.Linear(128, label)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "  def forward(self, data):\n",
        "    data = self.pool(functional.relu(self.conv1(data)))\n",
        "    data = torch.flatten(data, 1)\n",
        "    data = functional.relu(self.linear1(data))\n",
        "    data = functional.relu(self.linear2(data))\n",
        "    data = self.linear3(data)\n",
        "    #data = self.softmax(data)\n",
        "    return data\n",
        "softmax = Softmax(dim = 1)\n",
        "model_arr = []\n",
        "optimizer_arr = []\n",
        "for size in size_image:\n",
        "  model = Model(size, size)\n",
        "  model = model.to(device)\n",
        "  model = model.double()\n",
        "  model_arr.append(model)\n",
        "  model = Model2(size, size)\n",
        "  model = model.to(device)\n",
        "  model = model.double()\n",
        "  model_arr.append(model)\n",
        "for i in range(len(model_arr)):\n",
        "  optimizer_arr.append(Adam(model_arr[i].parameters(), lr = 0.00002))\n",
        "Cross_entrophy = nn.CrossEntropyLoss()\n",
        "#optimizer = SGD(model.parameters(), lr = 0.00001, momentum = 0.9)\n",
        "epochs_number = 12\n",
        "batch_size = 32\n",
        "for epoch in range(epochs_number):\n",
        "   for i in range(len(model_arr)):\n",
        "     split = int(X_train.shape[0] / batch_size)\n",
        "     random = np.random.permutation(split)\n",
        "     loss_sum = 0\n",
        "     for j in random:\n",
        "      Xj = X_train[j * batch_size : min(j * batch_size + batch_size, X_train.shape[0])]\n",
        "      Yj = Y_train[j * batch_size : min(j * batch_size + batch_size, X_train.shape[0])]\n",
        "      Xj = np.expand_dims(Xj, axis=-1)\n",
        "      Xj = tf.image.resize(Xj, [model_arr[i].row, model_arr[i].col])\n",
        "      Xj = np.array(Xj).reshape(Xj.shape[0], 1, Xj.shape[1] , Xj.shape[2]).astype(np.float32)/255.\n",
        "      Xj = torch.from_numpy(Xj)\n",
        "      Xj = torch.tensor(Xj, dtype = torch.double).to(device)\n",
        "      output = model_arr[i].forward(Xj)\n",
        "      loss = Cross_entrophy(output, Yj)\n",
        "      loss.backward()\n",
        "      optimizer_arr[i].step()\n",
        "      loss_sum += loss.item()\n",
        "      del loss\n",
        "      del output\n",
        "     if epoch % 3 == 0:\n",
        "       print(\"Loss value of model {} is : {}\".format(i, loss_sum))\n",
        "   if epoch % 3 == 0:\n",
        "     print(\" \")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss value of model 0 is : 1799.9515801204977\n",
            "Loss value of model 1 is : 1833.4544816340524\n",
            "Loss value of model 2 is : 1471.5895875867172\n",
            "Loss value of model 3 is : 1743.354845239232\n",
            "Loss value of model 4 is : 1228.0720250703307\n",
            "Loss value of model 5 is : 1769.0770613708728\n",
            " \n",
            "Loss value of model 0 is : 175.3290947886888\n",
            "Loss value of model 1 is : 355.12527933758844\n",
            "Loss value of model 2 is : 134.35932979816863\n",
            "Loss value of model 3 is : 406.86000575659165\n",
            "Loss value of model 4 is : 209.17089725742156\n",
            "Loss value of model 5 is : 531.9913612415816\n",
            " \n",
            "Loss value of model 0 is : 111.39843725747554\n",
            "Loss value of model 1 is : 194.30627293452497\n",
            "Loss value of model 2 is : 97.44182440652695\n",
            "Loss value of model 3 is : 216.83045791866917\n",
            "Loss value of model 4 is : 128.27309793509897\n",
            "Loss value of model 5 is : 266.9683225050497\n",
            " \n",
            "Loss value of model 0 is : 77.45658066706596\n",
            "Loss value of model 1 is : 121.31248356106242\n",
            "Loss value of model 2 is : 75.56627731106204\n",
            "Loss value of model 3 is : 121.98429550521092\n",
            "Loss value of model 4 is : 78.07219457102647\n",
            "Loss value of model 5 is : 146.4673708504141\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpnOpVvj5ZV7",
        "outputId": "7e8348dc-1d20-4cfb-83fd-af489e42f7b2"
      },
      "source": [
        "def score(X, Y, model, train_test, softmax):\n",
        "  multi_false = 0\n",
        "  false = [0 for i in range(len(model_arr))]\n",
        "  for i in range(X.shape[0]):\n",
        "    output = None\n",
        "    for j in range(len(model_arr)):\n",
        "      Xj = np.expand_dims(X[i], axis=-1)\n",
        "      #Xj = Xj.reshape(1, Xj.shape[0], Xj.shape[1])\n",
        "      Xj = tf.image.resize(Xj, [model_arr[j].row, model_arr[j].col])\n",
        "      Xj = np.array(Xj)\n",
        "      Xj = torch.from_numpy(Xj)\n",
        "      Xj = torch.tensor(Xj, dtype = torch.double).to(device)\n",
        "      Xj = torch.reshape(Xj, (1, 1, model_arr[j].row, model_arr[j].col))\n",
        "      output_j = model_arr[j].forward(Xj)\n",
        "      output_j = softmax(output_j)\n",
        "      predict_j = torch.argmax(output_j[0])\n",
        "      if predict_j != Y[i]:\n",
        "        false[j] += 1\n",
        "      if j == 0:\n",
        "        output = output_j\n",
        "      else:\n",
        "        output += output_j\n",
        "    output /= float(len(model_arr))\n",
        "    predict = torch.argmax(output[0])\n",
        "    if predict != Y[i]:\n",
        "      multi_false += 1\n",
        "  for i in range(len(model_arr)):\n",
        "    print(\"DNN model {} {} score is {}%\".format(i, train_test, (100 * (X.shape[0] - false[i]) / X.shape[0])))\n",
        "  print(\"Multi DNN model {} score is {}%\".format(train_test, (100 * (X.shape[0] -  multi_false) / X.shape[0])))\n",
        "score(X_train, Y_train, model, \"Train\", softmax)\n",
        "score(X_test, Y_test, model, \"Test\", softmax)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN model 0 Train score is 77.69%\n",
            "DNN model 1 Train score is 89.56833333333333%\n",
            "DNN model 2 Train score is 89.66333333333333%\n",
            "DNN model 3 Train score is 96.54166666666667%\n",
            "DNN model 4 Train score is 95.86833333333334%\n",
            "DNN model 5 Train score is 89.72%\n",
            "Multi DNN model Train score is 97.6%\n",
            "DNN model 0 Test score is 78.16%\n",
            "DNN model 1 Test score is 89.12%\n",
            "DNN model 2 Test score is 88.96%\n",
            "DNN model 3 Test score is 95.67%\n",
            "DNN model 4 Test score is 94.55%\n",
            "DNN model 5 Test score is 89.67%\n",
            "Multi DNN model Test score is 96.4%\n"
          ]
        }
      ]
    }
  ]
}